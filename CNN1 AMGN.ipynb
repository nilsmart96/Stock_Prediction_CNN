{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a171b7a",
   "metadata": {},
   "source": [
    "Final CNN1 model for Amgen Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4791f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Flatten, Input, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d758bb6",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6519ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AMGN_NN_60sec_ret.csv\", low_memory=False, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f316d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = df[\"TDay\"] + \" \" + df[\"IntraT\"]\n",
    "df.set_index(pd.DatetimeIndex(df['datetime']), inplace=True)\n",
    "\n",
    "df = df.drop(columns = {'Spread_Q', 'ret.Spread_Q', 'lag.Spread_Q'})\n",
    "df.rename(columns={\"ret.MidQ\": \"retMidQ\"}, inplace=True)\n",
    "\n",
    "df[\"MidQsq\"] = df.apply(lambda row: row.MidQ ** 2, axis=1)\n",
    "df[\"ret.MidQsq\"] = df.apply(lambda row: row.retMidQ ** 2, axis=1)\n",
    "df[\"MidQsqsq\"] = df.apply(lambda row: row.MidQ ** 3, axis=1)\n",
    "df['ret.MidQsqsq'] = df.apply(lambda row: row.retMidQ ** 3, axis=1)\n",
    "df['MidQsqsqsq'] = df.apply(lambda row: row.MidQ ** 4, axis=1)\n",
    "df['ret.MidQsqsqsq'] = df.apply(lambda row: row.retMidQ ** 4, axis=1)\n",
    "\n",
    "df = df.drop(columns = {'TDay', 'IntraT', 'datetime'})\n",
    "df.rename(columns={\"retMidQ\": \"ret.MidQ\"}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999b4d5",
   "metadata": {},
   "source": [
    "Creating the input X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = MinMaxScaler(feature_range=(0,255))\n",
    "df['X1sc'] = sc1.fit_transform(df['MidQ'].values.reshape(-1,1))\n",
    "df['X2sc'] = sc1.fit_transform(df['ret.MidQ'].values.reshape(-1,1))\n",
    "df['X3sc'] = sc1.fit_transform(df['lag.MidQ'].values.reshape(-1,1))\n",
    "df['X4sc'] = sc1.fit_transform(df['MidQsq'].values.reshape(-1,1))\n",
    "df['X5sc'] = sc1.fit_transform(df['ret.MidQsq'].values.reshape(-1,1))\n",
    "df['X6sc'] = sc1.fit_transform(df['MidQsqsq'].values.reshape(-1,1))\n",
    "df['X7sc'] = sc1.fit_transform(df['ret.MidQsqsq'].values.reshape(-1,1))\n",
    "df['X8sc'] = sc1.fit_transform(df['MidQsqsqsq'].values.reshape(-1,1))\n",
    "df['X9sc'] = sc1.fit_transform(df['ret.MidQsqsqsq'].values.reshape(-1,1))\n",
    "\n",
    "X1 = df.groupby(df.index.date)['X1sc'].apply(np.array).reset_index()\n",
    "X1 = X1.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X2 = df.groupby(df.index.date)['X2sc'].apply(np.array).reset_index()\n",
    "X2 = X2.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X3 = df.groupby(df.index.date)['X3sc'].apply(np.array).reset_index()\n",
    "X3 = X3.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X4 = df.groupby(df.index.date)['X4sc'].apply(np.array).reset_index()\n",
    "X4 = X4.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X5 = df.groupby(df.index.date)['X5sc'].apply(np.array).reset_index()\n",
    "X5 = X5.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X6 = df.groupby(df.index.date)['X6sc'].apply(np.array).reset_index()\n",
    "X6 = X6.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X7 = df.groupby(df.index.date)['X7sc'].apply(np.array).reset_index()\n",
    "X7 = X7.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X8 = df.groupby(df.index.date)['X8sc'].apply(np.array).reset_index()\n",
    "X8 = X8.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "X9 = df.groupby(df.index.date)['X9sc'].apply(np.array).reset_index()\n",
    "X9 = X9.rename(columns={\"index\": \"datetime\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89e425",
   "metadata": {},
   "source": [
    "Creating the labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adebd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgm = df.groupby(df.index.date)['ret.MidQ'].mean().reset_index()\n",
    "df_avgm.columns = ['datetime', 'y']\n",
    "\n",
    "sc2 = MinMaxScaler(feature_range=(0,1))\n",
    "df_avgm['ysc'] = sc2.fit_transform(df_avgm['y'].values.reshape(-1,1))\n",
    "\n",
    "df_avgc = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(X1, X2, on=\"datetime\"),\n",
    "                                                                                  X3, on=\"datetime\"),\n",
    "                                                                        X4, on=\"datetime\"),\n",
    "                                                               X5, on=\"datetime\"),\n",
    "                                                      X6, on=\"datetime\"),\n",
    "                                             X7, on=\"datetime\"),\n",
    "                                    X8, on=\"datetime\"),\n",
    "                            X9, on=\"datetime\"),\n",
    "                   df_avgm, on=\"datetime\")\n",
    "\n",
    "df_avgc = df_avgc.drop(columns = {'datetime', 'y'})\n",
    "\n",
    "df_avgc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6570c34",
   "metadata": {},
   "source": [
    "Connecting the right X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgc.ysc = df_avgc.ysc.shift(-1)\n",
    "df_avgc = df_avgc.dropna(axis='rows', how='any')\n",
    "\n",
    "df_avgc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c1231",
   "metadata": {},
   "source": [
    "Shaping the input X and split between taining and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1t = df_avgc['X1sc'].drop(df_avgc['X1sc'].index[100:123])\n",
    "X1t = np.asarray(X1t).flatten().tolist()\n",
    "X1t = np.array(X1t).reshape(100, 393, 1)\n",
    "\n",
    "X2t = df_avgc['X2sc'].drop(df_avgc['X2sc'].index[100:123])\n",
    "X2t = np.asarray(X2t).flatten().tolist()\n",
    "X2t = np.array(X2t).reshape(100, 393, 1)\n",
    "\n",
    "X3t = df_avgc['X3sc'].drop(df_avgc['X3sc'].index[100:123])\n",
    "X3t = np.asarray(X3t).flatten().tolist()\n",
    "X3t = np.array(X3t).reshape(100, 393, 1)\n",
    "\n",
    "X4t = df_avgc['X4sc'].drop(df_avgc['X4sc'].index[100:123])\n",
    "X4t = np.asarray(X4t).flatten().tolist()\n",
    "X4t = np.array(X4t).reshape(100, 393, 1)\n",
    "\n",
    "X5t = df_avgc['X5sc'].drop(df_avgc['X5sc'].index[100:123])\n",
    "X5t = np.asarray(X5t).flatten().tolist()\n",
    "X5t = np.array(X5t).reshape(100, 393, 1)\n",
    "\n",
    "X6t = df_avgc['X6sc'].drop(df_avgc['X6sc'].index[100:123])\n",
    "X6t = np.asarray(X6t).flatten().tolist()\n",
    "X6t = np.array(X6t).reshape(100, 393, 1)\n",
    "\n",
    "X7t = df_avgc['X7sc'].drop(df_avgc['X7sc'].index[100:123])\n",
    "X7t = np.asarray(X7t).flatten().tolist()\n",
    "X7t = np.array(X7t).reshape(100, 393, 1)\n",
    "\n",
    "X8t = df_avgc['X8sc'].drop(df_avgc['X8sc'].index[100:123])\n",
    "X8t = np.asarray(X8t).flatten().tolist()\n",
    "X8t = np.array(X8t).reshape(100, 393, 1)\n",
    "\n",
    "X9t = df_avgc['X9sc'].drop(df_avgc['X9sc'].index[100:123])\n",
    "X9t = np.asarray(X9t).flatten().tolist()\n",
    "X9t = np.array(X9t).reshape(100, 393, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X1t, X2t, X3t, X4t, X5t, X6t, X7t, X8t, X9t),\n",
    "                         axis=2)\n",
    "X_train = X_train.reshape(X_train.shape[0], 393, 9, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1p = df_avgc['X1sc'].drop(df_avgc['X1sc'].index[0:100])\n",
    "X1p = np.asarray(X1p).flatten().tolist()\n",
    "X1p = np.array(X1p).reshape(23, 393, 1)\n",
    "\n",
    "X2p = df_avgc['X2sc'].drop(df_avgc['X2sc'].index[0:100])\n",
    "X2p = np.asarray(X2p).flatten().tolist()\n",
    "X2p = np.array(X2p).reshape(23, 393, 1)\n",
    "\n",
    "X3p = df_avgc['X3sc'].drop(df_avgc['X3sc'].index[0:100])\n",
    "X3p = np.asarray(X3p).flatten().tolist()\n",
    "X3p = np.array(X3p).reshape(23, 393, 1)\n",
    "\n",
    "X4p = df_avgc['X4sc'].drop(df_avgc['X4sc'].index[0:100])\n",
    "X4p = np.asarray(X4p).flatten().tolist()\n",
    "X4p = np.array(X4p).reshape(23, 393, 1)\n",
    "\n",
    "X5p = df_avgc['X5sc'].drop(df_avgc['X5sc'].index[0:100])\n",
    "X5p = np.asarray(X5p).flatten().tolist()\n",
    "X5p = np.array(X5p).reshape(23, 393, 1)\n",
    "\n",
    "X6p = df_avgc['X6sc'].drop(df_avgc['X6sc'].index[0:100])\n",
    "X6p = np.asarray(X6p).flatten().tolist()\n",
    "X6p = np.array(X6p).reshape(23, 393, 1)\n",
    "\n",
    "X7p = df_avgc['X7sc'].drop(df_avgc['X7sc'].index[0:100])\n",
    "X7p = np.asarray(X7p).flatten().tolist()\n",
    "X7p = np.array(X7p).reshape(23, 393, 1)\n",
    "\n",
    "X8p = df_avgc['X8sc'].drop(df_avgc['X8sc'].index[0:100])\n",
    "X8p = np.asarray(X8p).flatten().tolist()\n",
    "X8p = np.array(X8p).reshape(23, 393, 1)\n",
    "\n",
    "X9p = df_avgc['X9sc'].drop(df_avgc['X9sc'].index[0:100])\n",
    "X9p = np.asarray(X9p).flatten().tolist()\n",
    "X9p = np.array(X9p).reshape(23, 393, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567cf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X1p, X2p, X3p, X4p, X5p, X6p, X7p, X8p, X9p),\n",
    "                        axis=2)\n",
    "X_test = X_test.reshape(X_test.shape[0], 393, 9, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852d54a",
   "metadata": {},
   "source": [
    "Shaping the labels y and split between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgc = df_avgc[['X1sc', 'X2sc', 'X3sc', 'X4sc', 'X5sc', 'X6sc', 'X7sc', 'X8sc', 'X9sc', 'ysc']]\n",
    "ym = df_avgc.iloc[:, 9:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa572cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymt = []\n",
    "for i in range(0, 100):\n",
    "    ymt.append(ym[i, 0])\n",
    "    \n",
    "ymt = np.array(ymt)\n",
    "ym_train = np.reshape(ymt, (ymt.shape[0], 1))\n",
    "\n",
    "ym_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b23c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymp = []\n",
    "for i in range(100, 123):\n",
    "    ymp.append(ym[i, 0])\n",
    "    \n",
    "ymp = np.array(ymp)\n",
    "ym_test = np.reshape(ymp, (ymp.shape[0], 1))\n",
    "\n",
    "ym_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5eff10",
   "metadata": {},
   "source": [
    "Actual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f95bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_HEIGHT = 393\n",
    "IM_WIDTH = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputModel():\n",
    "    \n",
    "    def make_default_hidden_layers(self, inputs):\n",
    "    \n",
    "        x = Conv2D(16, (3, 3), padding=\"same\",\n",
    "                   kernel_initializer=\"HeUniform\")(inputs)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0)(x)        \n",
    "        \n",
    "        x = Conv2D(32, (3, 3), padding=\"same\",\n",
    "                   kernel_initializer=\"HeUniform\")(x)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0)(x)\n",
    "                \n",
    "        x = Conv2D(64, (3, 3), padding=\"same\",\n",
    "                   kernel_initializer=\"HeUniform\")(x)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0)(x)\n",
    "        \n",
    "        x = Conv2D(128, (3, 3), padding=\"same\",\n",
    "                   kernel_initializer=\"HeUniform\")(x)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 1))(x)\n",
    "        x = Dropout(0)(x)\n",
    "        \n",
    "        x = Conv2D(256, (3, 3), padding=\"same\",\n",
    "                   kernel_initializer=\"HeUniform\")(x)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 1))(x)\n",
    "        x = Dropout(0)(x)\n",
    "        \n",
    "        return x    \n",
    "    \n",
    "    def build_retmean_branch(self, inputs):\n",
    "\n",
    "        x = self.make_default_hidden_layers(inputs)        \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(64)(x)\n",
    "        x = Activation(\"elu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"sigmoid\", name=\"retmean_output\")(x)        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def assemble_full_model(self, width, height):\n",
    "\n",
    "        input_shape = (height, width, 1)        \n",
    "        inputs = Input(shape=input_shape)\n",
    "        \n",
    "        retmean_branch = self.build_retmean_branch(inputs)       \n",
    "        \n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = [retmean_branch],\n",
    "                     name=\"CNN_Model_4\")        \n",
    "        \n",
    "        return model\n",
    "    \n",
    "model = MultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ab688",
   "metadata": {},
   "source": [
    "Training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 0.0001\n",
    "epochs = 750\n",
    "batch_size = 10\n",
    "\n",
    "opt = RMSprop(learning_rate=init_lr, decay=init_lr / epochs)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "            loss={'retmean_output': 'mse'},\n",
    "            loss_weights={'retmean_output': 0.1},\n",
    "            metrics={'retmean_output': 'mae'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc92de",
   "metadata": {},
   "source": [
    "Restarting the random weight initialization after each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model): #if you're using a model as a layer\n",
    "            reset_weights(layer) #apply function recursively\n",
    "            continue\n",
    "\n",
    "        #where are the initializers?\n",
    "        if hasattr(layer, 'cell'):\n",
    "            init_container = layer.cell\n",
    "        else:\n",
    "            init_container = layer\n",
    "\n",
    "        for key, initializer in init_container.__dict__.items():\n",
    "            if \"initializer\" not in key: #is this item an initializer?\n",
    "                  continue #if no, skip it\n",
    "\n",
    "            # find the corresponding variable, like the kernel or the bias\n",
    "            if key == 'recurrent_initializer': #special case check\n",
    "                var = getattr(init_container, 'recurrent_kernel')\n",
    "            else:\n",
    "                var = getattr(init_container, key.replace(\"_initializer\", \"\"))\n",
    "\n",
    "            var.assign(initializer(var.shape, var.dtype))\n",
    "            #use the initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985d32c",
   "metadata": {},
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predres=[]\n",
    "predstd=[]\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    history = model.fit(x=X_train, y={\"retmean_output\": ym_train},\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs)\n",
    "    \n",
    "    res = model.predict(X_test)\n",
    "    predres.append(res)\n",
    "    std = np.std(predres)\n",
    "    predstd.append(std)\n",
    "    \n",
    "    model.reset_states()\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a8770",
   "metadata": {},
   "source": [
    "Standard deviation after each time the model is training and forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d113f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 2), dpi=80)\n",
    "plt.plot(predstd, color = 'black')\n",
    "plt.title('Amgen Inc.')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Standard deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64449efd",
   "metadata": {},
   "source": [
    "Shaping the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9361d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(list(map(np.ravel, predres)))\n",
    "meanres = df_res.mean(axis=0)\n",
    "meanres = np.array(meanres)\n",
    "meanres = np.reshape(meanres, (meanres.shape[0], 1))\n",
    "\n",
    "meanres20d = meanres[:20]\n",
    "ym_test20d = ym_test[:20]\n",
    "\n",
    "df_meanres20d = pd.DataFrame({'predictionsc': meanres20d[:, 0]})\n",
    "df_ym_test20d = pd.DataFrame({'realsc': ym_test20d[:, 0]})\n",
    "\n",
    "df_meanres20d['prediction'] = sc2.inverse_transform(df_meanres20d['predictionsc'].values.reshape(-1,1))\n",
    "df_ym_test20d['real'] = sc2.inverse_transform(df_ym_test20d['realsc'].values.reshape(-1,1))\n",
    "\n",
    "print(df_meanres20d)\n",
    "print(df_ym_test20d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ed83f",
   "metadata": {},
   "source": [
    "Visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 2), dpi=80)\n",
    "plt.plot(df_ym_test20d['real'], color='black', label='real')\n",
    "plt.plot(df_meanres20d['prediction'], color='green', label='prediction')\n",
    "plt.xticks(np.arange(0, 20+1, 2.0))\n",
    "plt.title('Amgen Inc.')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Simple mean return')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c6508",
   "metadata": {},
   "source": [
    "Mean squared error of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_res = np.subtract(df_ym_test20d['real'], df_meanres20d['prediction'])\n",
    "sq_res = np.square(diff_res)\n",
    "mseres = sq_res.mean()\n",
    "\n",
    "print(mseres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_res = np.subtract(df_ym_test20d['realsc'], df_meanres20d['predictionsc'])\n",
    "sq_res = np.square(diff_res)\n",
    "mseres_sc = sq_res.mean()\n",
    "\n",
    "print(mseres_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f23d20",
   "metadata": {},
   "source": [
    "Saving the results and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meanres20d.to_csv(r'C:\\Users\\nmart\\Documents\\Office\\ZU\\S8\\Bachelor-Thesis\\Nils_Test_Daten\\Nils_Test_Daten\\Finales\\CNN1_res_AMGN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ac3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/CNN1_AMGN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('FS_Base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "092fd3b47a62a288d64e0d56cb1d943a7dfc85b85fdb59434f57bdf2cec50c7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
